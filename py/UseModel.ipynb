{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型调用\n",
    "import joblib\n",
    "model_load=joblib.load(\"C:\\\\Users\\\\Administrator\\\\keshe\\\\0516\\\\cwru.model\")#模型的地址\n",
    "\n",
    "PATH = 'F:/dataset'#数据集目录地址\n",
    "#修改此处路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要的已经定义好的函数\n",
    "def co(n):\n",
    "    c0=0\n",
    "    c1=0\n",
    "    c2=0\n",
    "    c3=0\n",
    "    for x in n:\n",
    "        if x=='0':\n",
    "            c0=c0+1\n",
    "        elif x=='1':\n",
    "            c1=c1+1\n",
    "        elif x=='2':\n",
    "            c2=c2+1\n",
    "        elif x=='3':\n",
    "            c3=c3+1\n",
    "    max1=max(c0,c1,c2,c3)\n",
    "    if max1==c1:\n",
    "        return('1')\n",
    "    elif max1==c2:\n",
    "        return('2')\n",
    "    elif max1==c3:\n",
    "        return('3')\n",
    "    elif max1==c0:\n",
    "        return('0')\n",
    "    \n",
    "from scipy import stats,signal,fftpack\n",
    "from pywt import wavedec\n",
    "\"\"\"特征提取\n",
    " 时域：\n",
    " 均值，标准差，最大值，最小值，均方根，峰峰值，中位数，四分位差，百分位差，\n",
    " 偏度，峰度，方差，整流平均值，方根幅值，波形因子，峰值因子，脉冲值，裕度\n",
    " 频域：\n",
    " 均值，标准差，最大值，最小值，均方根，中位数，四分位差，百分位差\n",
    " f2 f3 f4反映频谱集中程度\n",
    " f5 f6 f7 f8反映主频带位置\n",
    " 5级小波变换，最后输出6个能量特征和其归一化能量特征\"\"\"\n",
    "    \n",
    "columns = ['time_mean','time_std','time_max','time_min','time_rms','time_ptp','time_median',\n",
    "                                     'time_iqr','time_pr','time_skew','time_kurtosis','time_var','time_amp',\n",
    "                                     'time_smr','time_wavefactor','time_peakfactor','time_pulse','time_margin',\n",
    "                                     'freq_mean','freq_std','freq_max','freq_min','freq_rms','freq_median',\n",
    "                                     'freq_iqr','freq_pr','freq_f2','freq_f3','freq_f4','freq_f5','freq_f6','freq_f7',\n",
    "                                     'freq_f8','ener_cA5','ener_cD1','ener_cD2','ener_cD3','ener_cD4','ener_cD5',\n",
    "                                     'ratio_cA5','ratio_cD1','ratio_cD2','ratio_cD3','ratio_cD4','ratio_cD5']\n",
    "data_names = ['DE_','FE_']\n",
    "new_columns = []\n",
    "for data_name in data_names:\n",
    "    new_columns.extend([data_name+j for j in columns])\n",
    "\n",
    "\n",
    "def featuring(this_file_data,windowlen):\n",
    "    n_line = this_file_data.shape[0]\n",
    "    features = []\n",
    "    for i in range (0,n_line,windowlen):\n",
    "        if (n_line - i)/windowlen >= 1:\n",
    "            df = this_file_data.loc[i:i+windowlen,['DE_time','FE_time']]\n",
    "            feature_list = []\n",
    "            for col in df.columns:\n",
    "                df_line = df[col]\n",
    "                time_mean = df_line.mean()                                           \n",
    "                time_std = df_line.std()\n",
    "                time_max = df_line.max()\n",
    "                time_min = df_line.min()\n",
    "                time_rms = np.sqrt(np.square(df_line).mean())\n",
    "                time_ptp = time_max-time_min \n",
    "                time_median = np.median(df_line)\n",
    "                time_iqr = np.percentile(df_line,75)-np.percentile(df_line,25)\n",
    "                time_pr = np.percentile(df_line,90)-np.percentile(df_line,10)\n",
    "                time_skew = stats.skew(df_line)\n",
    "                time_kurtosis = stats.kurtosis(df_line)\n",
    "                time_var = np.var(df_line)\n",
    "                time_amp = np.abs(df_line).mean()\n",
    "                time_smr = np.square(np.sqrt(np.abs(df_line)).mean())\n",
    "#               下面四个特征需要注意分母为0或接近0问题，可能会发生报错\n",
    "                time_wavefactor = time_rms/time_amp\n",
    "                time_peakfactor = time_max/time_rms\n",
    "                time_pulse = time_max/time_amp\n",
    "                time_margin = time_max/time_smr\n",
    "#               采样频率25600Hz\n",
    "                df_fftline = fftpack.fft(df[col])\n",
    "                freq_fftline = fftpack.fftfreq(len(df[col]),1/25600)\n",
    "                df_fftline = abs(df_fftline[freq_fftline>=0])\n",
    "                freq_fftline = freq_fftline[freq_fftline>=0]\n",
    "                freq_mean = df_fftline.mean()\n",
    "                freq_std = df_fftline.std()\n",
    "                freq_max = df_fftline.max()\n",
    "                freq_min = df_fftline.min()\n",
    "                freq_rms = np.sqrt(np.square(df_fftline).mean())\n",
    "                freq_median = np.median(df_fftline)\n",
    "                freq_iqr = np.percentile(df_fftline,75)-np.percentile(df_fftline,25)\n",
    "                freq_pr = np.percentile(df_fftline,90)-np.percentile(df_fftline,10)\n",
    "                freq_f2 = np.square((df_fftline-freq_mean)).sum()/(len(df_fftline)-1)\n",
    "                freq_f3 = pow((df_fftline-freq_mean),3).sum()/(len(df_fftline)*pow(freq_f2,1.5))\n",
    "                freq_f4 = pow((df_fftline-freq_mean),4).sum()/(len(df_fftline)*pow(freq_f2,2))\n",
    "                freq_f5 = np.multiply(freq_fftline,df_fftline).sum()/df_fftline.sum()\n",
    "                freq_f6 = np.sqrt(np.multiply(np.square(freq_fftline),df_fftline).sum())/df_fftline.sum()\n",
    "                freq_f7 = np.sqrt(np.multiply(pow(freq_fftline,4),df_fftline).sum())/np.multiply(np.square(freq_fftline),df_fftline).sum()\n",
    "                freq_f8 = np.multiply(np.square(freq_fftline),df_fftline).sum()/np.sqrt(np.multiply(pow(freq_fftline,4),df_fftline).sum()*df_fftline.sum())\n",
    "                #----------  timefreq-domain feature,12\n",
    "                # 5级小波变换，最后输出6个能量特征和其归一化能量特征\n",
    "                cA5, cD5, cD4, cD3, cD2, cD1 = wavedec(df[col], 'db10', level=5)\n",
    "                ener_cA5 = np.square(cA5).sum()\n",
    "                ener_cD5 = np.square(cD5).sum()\n",
    "                ener_cD4 = np.square(cD4).sum()\n",
    "                ener_cD3 = np.square(cD3).sum()\n",
    "                ener_cD2 = np.square(cD2).sum()\n",
    "                ener_cD1 = np.square(cD1).sum()\n",
    "                ener = ener_cA5 + ener_cD1 + ener_cD2 + ener_cD3 + ener_cD4 + ener_cD5\n",
    "                ratio_cA5 = ener_cA5/ener\n",
    "                ratio_cD5 = ener_cD5/ener\n",
    "                ratio_cD4 = ener_cD4/ener\n",
    "                ratio_cD3 = ener_cD3/ener\n",
    "                ratio_cD2 = ener_cD2/ener\n",
    "                ratio_cD1 = ener_cD1/ener\n",
    "\n",
    "                feature_list.extend([time_mean,time_std,time_max,time_min,time_rms,time_ptp,time_median,\n",
    "                                     time_iqr,time_pr,time_skew,time_kurtosis,time_var,time_amp,\n",
    "                                     time_smr,time_wavefactor,time_peakfactor,time_pulse,time_margin,\n",
    "                                     freq_mean,freq_std,freq_max,freq_min,freq_rms,freq_median,\n",
    "                                     freq_iqr,freq_pr,freq_f2,freq_f3,freq_f4,freq_f5,freq_f6,freq_f7,\n",
    "                                     freq_f8,ener_cA5,ener_cD1,ener_cD2,ener_cD3,ener_cD4,ener_cD5,\n",
    "                                     ratio_cA5,ratio_cD1,ratio_cD2,ratio_cD3,ratio_cD4,ratio_cD5])\n",
    "            features.append(feature_list)\n",
    "    features = np.asarray(features)\n",
    "    return features\n",
    "\n",
    "\n",
    "def Trainfeaturing(train_files,train_data,windowlen):\n",
    "    flag = 0\n",
    "    for label in range(len(train_files)):\n",
    "        this_label_data = train_data[train_data.label == label]\n",
    "        n_file = max(this_label_data.file)\n",
    "        for file_index in range(1,n_file+1):\n",
    "            this_file_data = this_label_data[this_label_data.file == file_index]\n",
    "            if flag == 0:\n",
    "                features = featuring(this_file_data,windowlen)\n",
    "                flag += 1\n",
    "                labels = [label for j in range(features.shape[0])]\n",
    "            else:\n",
    "                new_features = featuring(this_file_data,windowlen)\n",
    "                features = np.concatenate((features, new_features), axis=0)\n",
    "                labels.extend([label for j in range(new_features.shape[0])])\n",
    "    features = np.asarray(features)\n",
    "    labels = np.asarray(labels)\n",
    "    return features,labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "file 1\n",
      "0\n",
      "file 2\n",
      "0\n",
      "file 3\n",
      "3\n",
      "file 4\n",
      "1\n",
      "file 5\n",
      "0\n",
      "file 6\n",
      "0\n",
      "file 7\n",
      "0\n",
      "file 8\n",
      "2\n",
      "file 9\n",
      "0\n",
      "file 10\n",
      "1\n",
      "file 11\n",
      "0\n",
      "file 12\n",
      "0\n",
      "file 13\n",
      "0\n",
      "file 14\n",
      "0\n",
      "file 15\n",
      "0\n",
      "file 16\n",
      "0\n",
      "file 17\n",
      "3\n",
      "file 18\n",
      "0\n",
      "file 19\n",
      "0\n",
      "file 20\n",
      "0\n",
      "file 21\n",
      "1\n",
      "file 22\n",
      "2\n",
      "file 23\n",
      "0\n",
      "file 24\n",
      "0\n",
      "file 25\n",
      "0\n",
      "file 26\n",
      "0\n",
      "file 27\n",
      "0\n",
      "file 28\n",
      "0\n",
      "file 29\n",
      "0\n",
      "file 30\n",
      "0\n",
      "file 31\n",
      "0\n",
      "file 32\n",
      "0\n",
      "file 33\n",
      "0\n",
      "file 34\n",
      "0\n",
      "file 35\n",
      "0\n",
      "file 36\n",
      "3\n",
      "file 37\n",
      "3\n",
      "file 38\n",
      "0\n",
      "file 39\n",
      "0\n",
      "file 40\n",
      "0\n",
      "file 41\n",
      "0\n",
      "file 42\n",
      "2\n",
      "file 43\n",
      "0\n",
      "file 44\n",
      "0\n",
      "file 45\n",
      "0\n",
      "file 46\n",
      "0\n",
      "file 47\n",
      "0\n",
      "file 48\n",
      "0\n",
      "file 49\n",
      "0\n",
      "file 50\n",
      "0\n",
      "file 51\n",
      "0\n",
      "file 52\n",
      "0\n",
      "file 53\n",
      "0\n",
      "file 54\n",
      "2\n",
      "file 55\n",
      "0\n",
      "file 56\n",
      "0\n",
      "file 57\n",
      "0\n",
      "file 58\n",
      "0\n",
      "file 59\n",
      "0\n",
      "file 60\n",
      "1\n",
      "file 61\n",
      "0\n",
      "file 62\n",
      "1\n",
      "file 63\n",
      "0\n",
      "file 64\n",
      "0\n",
      "file 65\n",
      "3\n",
      "file 66\n",
      "0\n",
      "file 67\n",
      "2\n",
      "file 68\n",
      "2\n",
      "file 69\n",
      "1\n",
      "file 70\n",
      "0\n",
      "file 71\n",
      "2\n",
      "file 72\n",
      "0\n",
      "file 73\n",
      "0\n",
      "file 74\n",
      "0\n",
      "file 75\n",
      "2\n",
      "file 76\n",
      "0\n",
      "file 77\n",
      "0\n",
      "file 78\n",
      "0\n",
      "file 79\n",
      "2\n",
      "file 80\n",
      "0\n",
      "file 81\n",
      "0\n",
      "file 82\n",
      "0\n",
      "file 83\n",
      "2\n",
      "file 84\n",
      "0\n",
      "file 85\n",
      "0\n",
      "file 86\n",
      "0\n",
      "file 87\n",
      "0\n",
      "file 88\n",
      "0\n",
      "file 89\n",
      "0\n",
      "file 90\n",
      "0\n",
      "file 91\n",
      "0\n",
      "file 92\n",
      "0\n",
      "file 93\n",
      "0\n",
      "file 94\n",
      "0\n",
      "file 95\n",
      "0\n",
      "file 96\n",
      "0\n",
      "file 97\n",
      "0\n",
      "file 98\n",
      "0\n",
      "file 99\n",
      "0\n",
      "file 100\n",
      "0\n",
      "file 101\n",
      "0\n",
      "file 102\n",
      "0\n",
      "file 103\n",
      "0\n",
      "file 104\n",
      "3\n",
      "file 105\n",
      "3\n",
      "file 106\n",
      "1\n",
      "file 107\n",
      "0\n",
      "file 108\n",
      "1\n",
      "file 109\n",
      "0\n",
      "file 110\n",
      "0\n",
      "file 111\n",
      "0\n",
      "file 112\n",
      "0\n",
      "file 113\n",
      "0\n",
      "file 114\n",
      "0\n",
      "file 115\n",
      "1\n",
      "file 116\n",
      "2\n",
      "file 117\n",
      "2\n",
      "file 118\n",
      "0\n",
      "file 119\n",
      "3\n",
      "file 120\n",
      "2\n",
      "file 121\n",
      "0\n",
      "file 122\n",
      "1\n",
      "file 123\n",
      "0\n",
      "file 124\n",
      "1\n",
      "file 125\n",
      "0\n",
      "file 126\n",
      "0\n",
      "file 127\n",
      "0\n",
      "file 128\n",
      "3\n",
      "file 129\n",
      "0\n",
      "file 130\n",
      "1\n",
      "file 131\n",
      "0\n",
      "file 132\n",
      "0\n",
      "file 133\n",
      "1\n",
      "file 134\n",
      "0\n",
      "file 135\n",
      "0\n",
      "file 136\n",
      "0\n",
      "file 137\n",
      "0\n",
      "file 138\n",
      "0\n",
      "file 139\n",
      "0\n",
      "file 140\n",
      "3\n",
      "file 141\n",
      "2\n",
      "file 142\n",
      "3\n",
      "succeed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "m='/test/TEST'#/test为存储测试数据的文件夹名，TEST为文件名数字前的TEST\n",
    "a=PATH+m\n",
    "b='.csv'\n",
    "windowlen=1750\n",
    "\n",
    "print('Predicting...')\n",
    "import csv\n",
    "f = open(\"result.csv\", \"w\",encoding='utf-8',newline='') \n",
    "csv_writer = csv.writer(f)\n",
    "f.close()\n",
    "#清空文件\n",
    "f = open(\"result.csv\", \"a\",encoding='utf-8',newline='') \n",
    "csv_writer = csv.writer(f)\n",
    "csv_writer.writerow([\"filename\",\"label\"])\n",
    "\n",
    "params={}\n",
    "for s in range(1,143):\n",
    "    print('file',s)\n",
    "    temp=a+str(s)+b\n",
    "    temp2=\"TEST\"+str(s)\n",
    "    params['testdata_path'] = str(temp)\n",
    "    data7 = pd.DataFrame(pd.read_csv(params['testdata_path']))\n",
    "    X_test = featuring(data7,1750)\n",
    "    y_prob = model_load.predict(X_test, num_iteration=model_load.best_iteration)\n",
    "\n",
    "    y_pred = [list(x).index(max(x)) for x in y_prob]\n",
    "    y_pred = str(y_pred)\n",
    "    \n",
    "    y_pred=y_pred.replace(\"[\", \"\");\n",
    "    y_pred=y_pred.replace(\"]\", \"\");\n",
    "    print(co(y_pred))\n",
    "    csv_writer = csv.writer(f)\n",
    "\n",
    "    csv_writer.writerow([temp2,co(y_pred)])\n",
    "f.close()\n",
    "print(\"succeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
